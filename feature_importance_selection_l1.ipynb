{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a66d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import csv\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f933dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_feature(model,file_numb):\n",
    "    df = pd.read_csv(r'C:\\Users\\johnk\\OneDrive\\Desktop\\project\\python project\\kaggle\\amex-default-prediction\\new_train\\train_{0}.csv'.format(file_numb))\n",
    "    feature = df.iloc[:,1:-1]\n",
    "    label = pd.DataFrame(df['target'], columns=['target'])\n",
    "    np_label =  np.array(label).T[0]\n",
    "    for y in feature_name:\n",
    "        feature[y]=feature[y].fillna(feature[y].mean())\n",
    "    mdl = model(max_iter =20**9)\n",
    "    mdl.fit(feature, np_label)\n",
    "    feature_importance = permutation_importance(mdl, feature, np_label, n_repeats=10)\n",
    "    fi = pd.DataFrame(feature_importance.importances_mean, index = feature.columns, columns = ['importance'])\n",
    "    important_l1= fi.loc[fi['importance']>0].index\n",
    "    return important_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ad468cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_important_l1(model, file_number):\n",
    "    i = pd.read_csv('important_l1.csv')\n",
    "    important_l1 = get_important_feature(model, file_number)\n",
    "    if model == GradientBoostingClassifier:\n",
    "        for x in important_l1:\n",
    "            i.loc[0,x]+=1\n",
    "    if model == LogisticRegression:\n",
    "        for x in important_l1:\n",
    "            i.loc[1,x]+=1\n",
    "    i.to_csv('important_l1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f03692d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [GradientBoostingClassifier,LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d32f9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0  518.9924819469452 second \n",
      "1\n",
      "1  495.8296914100647 second \n",
      "2\n",
      "2  587.721574306488 second \n",
      "3\n",
      "3  515.8463206291199 second \n",
      "4\n",
      "4  482.4471125602722 second \n",
      "5\n",
      "5  475.2628047466278 second \n",
      "6\n",
      "6  485.5480716228485 second \n"
     ]
    }
   ],
   "source": [
    "for x in range(0,7):\n",
    "    start_time = time.time()\n",
    "    important_l1 = update_important_l1(LogisticRegression,x)\n",
    "    print(x, end=' ')\n",
    "    print(\" %s second \" %(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
