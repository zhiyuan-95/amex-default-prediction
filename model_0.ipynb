{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b8aef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "374b82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def level_1_predictor(t_train,y, model):\n",
    "    leng = int(len(t_train)/2)\n",
    "    t_a, t_b= t_train[:leng], t_train[leng:]\n",
    "    tg_a, tg_b = y[:leng], y[leng:]\n",
    "    if model == LogisticRegression:\n",
    "        m1 = model(max_iter = 20**9)\n",
    "        m2 = model(max_iter = 20**9)\n",
    "    else:\n",
    "        m1 = model()\n",
    "        m2 = model()\n",
    "    m1.fit(t_a,tg_a)\n",
    "    tp_b = [i[1] for i in m1.predict_proba(t_b)]\n",
    "    m2.fit(t_b,tg_b)\n",
    "    tp_a = [i[1] for i in m2.predict_proba(t_a)]\n",
    "    \n",
    "    tp = [[x] for x in np.hstack((tp_a,tp_b))]\n",
    "    \n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa1cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updata_important_l1():\n",
    "    i = pd.read_csv('important_l1.csv')\n",
    "    for x in important_l1:\n",
    "        i[x]+=1\n",
    "    i.to_csv('important_l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4bedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def stder(X):\n",
    "    cols = X.columns\n",
    "    stder = StandardScaler(copy=True, with_mean = True, with_std = True)\n",
    "    stder.fit(X)\n",
    "    return pd.DataFrame(stder.transform(X), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae64b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training(n,m):\n",
    "    files= []\n",
    "    for x in range(n,m):\n",
    "        files.append(pd.read_csv(r'C:\\Users\\johnk\\OneDrive\\Desktop\\project\\python project\\kaggle\\amex-default-prediction\\new_train\\train_{0}.csv'.format(x)))\n",
    "    training_set = pd.concat(files, axis = 0)\n",
    "    training_set.index = [x for x in range(training_set.shape[0])]\n",
    "    training_label = training_set['target']\n",
    "    training_feature = training_set.iloc[:,1:-1]\n",
    "    for x in training_feature.columns:\n",
    "        training_feature[x]=training_feature[x].fillna(training_feature[x].mean())    \n",
    "    return training_feature, np.array(training_label).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d181f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_validation(data, labels, model, error_function=roc_auc_score,folds=5, **model_args):\n",
    "    kf = KFold(n_splits=folds, random_state=None, shuffle = True)\n",
    "    score = []\n",
    "    y = np.array(labels)\n",
    "    if model == LogisticRegression:\n",
    "        M = model(max_iter = 20**9)\n",
    "    else:\n",
    "        M = model()\n",
    "    for train_index,test_index in kf.split(data):\n",
    "        x_training_set = data.iloc[train_index]\n",
    "        y_training_set = y[train_index]\n",
    "        x_test_set = data.iloc[test_index]\n",
    "        y_test_set = y[test_index]\n",
    "        M.fit(np.array(x_training_set), y_training_set)\n",
    "        y_pred = M.predict(np.array(x_test_set))\n",
    "        score.append(error_function(y_test_set,y_pred)) \n",
    "        print('.',end=' ')\n",
    "    average_error = round(sum(score)/folds,4)\n",
    "    return average_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dde4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_splitor(important_feature,model = GradientBoostingClassifier):\n",
    "    delinquency=[]\n",
    "    spend = []\n",
    "    payment = []\n",
    "    balance = []\n",
    "    risk = []\n",
    "    std = []\n",
    "    mean = []\n",
    "    _25 = []\n",
    "    _50 = []\n",
    "    _75 = []\n",
    "    _min = []\n",
    "    _max = []\n",
    "\n",
    "    for x in important_feature:\n",
    "        if x[0]=='D':\n",
    "            delinquency.append(x)\n",
    "        if x[0]=='S':\n",
    "            spend.append(x)\n",
    "        if x[0]=='P':\n",
    "            payment.append(x)\n",
    "        if x[0]=='B':\n",
    "            balance.append(x)\n",
    "        if x[0]=='R':\n",
    "            risk.append(x)\n",
    "        if x[-3:]=='std':\n",
    "            std.append(x)\n",
    "        elif x[-3:]=='25%':\n",
    "            _25.append(x)\n",
    "        elif x[-3:]=='75%':\n",
    "            _75.append(x)\n",
    "        elif x[-3:]=='50%':\n",
    "            _50.append(x)\n",
    "        elif x[-3:]=='min':\n",
    "            _min.append(x)\n",
    "        elif x[-3:]=='max':\n",
    "            _max.append(x)\n",
    "        else:\n",
    "            mean.append(x)  \n",
    "    feature_sets = {'delinquency':delinquency,'spend':spend,'payment':payment,'balance':balance,'risk':risk,'std':std,\n",
    "                    'mean':mean,'_25':_25,'_50':_50,'_75':_75,'_min':_min,'_max':_max}\n",
    "    return feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f638f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_predictor(important_feature, label,feature_sets, model = GradientBoostingClassifier):\n",
    "    column_name = list(feature_sets.keys())\n",
    "    new_feature = pd.DataFrame(columns = column_name)\n",
    "    for x in column_name:\n",
    "        l1_feature = np.array(important_feature[feature_sets[x]])\n",
    "        new_feature[x] = level_1_predictor(l1_feature,label, model)\n",
    "    return new_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27681162",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b07d8",
   "metadata": {},
   "source": [
    "### preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecf607da",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train, label_train = prepare_training(4,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109cdf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train_std = stder(feature_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f89f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GradientBoostingClassifier,LogisticRegression,RandomForestClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f8ce8",
   "metadata": {},
   "source": [
    "### first glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415bc103",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.DataFrame(columns = ['std', 'No_std'], index = ['GradientBoostingClassifier', 'LogisticRegression', 'RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f84d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . GradientBoostingClassifier\n",
      ". "
     ]
    }
   ],
   "source": [
    "for x in models:\n",
    "    score.loc[x.__name__,'std']=cross_validation(feature_train_std, label_train, x)\n",
    "    print(x.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12583ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score.loc[x.__name__,'No_std']=cross_validation(feature_train, label_train, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0177d463",
   "metadata": {},
   "source": [
    "## feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_feature(X,Y,mdl = GradientBoostingClassifier):\n",
    "    start_time = time.time()\n",
    "    model = mdl()\n",
    "    model.fit(X,Y)\n",
    "    feature_importance = permutation_importance(model, X,Y, n_repeats=10)\n",
    "    fi = pd.DataFrame(feature_importance.importances_mean, index = X.columns, columns = ['importance'])\n",
    "    important_fe= X[fi.loc[fi['importance']>0].index]\n",
    "    unimportant_fe = X[fi.loc[fi['importance']<=0].index]\n",
    "    print(\" %s second \" %(time.time()-start_time))\n",
    "    return important_fe, unimportant_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_fe, unimpt_fe = get_important_feature(feature_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146152cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_fe_std, unimpt_fe_std = get_important_feature(feature_train_std, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32e9e8",
   "metadata": {},
   "source": [
    "### predict with imortant features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160aa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = pd.DataFrame(columns = ['std', 'No_std'], index = ['GradientBoostingClassifier', 'LogisticRegression', 'RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score1.loc[x.__name__,'std']=cross_validation(impt_fe_std, label_train, x)\n",
    "    print(x.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72066f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score1.loc[x.__name__,'No_std']=cross_validation(impt_fe, label_train, x)\n",
    "    print(x.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec86213",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e327b4",
   "metadata": {},
   "source": [
    "###  stacking, create l2 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b16564",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = feature_splitor(impt_fe)\n",
    "feature_set_std = feature_splitor(impt_fe_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b02791",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_feature = l1_predictor(impt_fe, label_train,feature_set)\n",
    "l2_feature_std =l1_predictor(impt_fe_std, label_train,feature_set_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d773f0",
   "metadata": {},
   "source": [
    "### predict with l2 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = pd.DataFrame(columns = ['std_l2', 'No_std_l2'], index = ['GradientBoostingClassifier', 'LogisticRegression', 'RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cfa20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score2.loc[x.__name__,'std_l2']=cross_validation(l2_feature, label_train, x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2850436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score2.loc[x.__name__,'No_std_l2']=cross_validation(l2_feature_std, label_train, x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525bd82c",
   "metadata": {},
   "source": [
    "### combine important_feature with L2 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804f446",
   "metadata": {},
   "outputs": [],
   "source": [
    "score3 = pd.DataFrame(columns = ['meta', 'meta_std'], index = ['GradientBoostingClassifier', 'LogisticRegression', 'RandomForestClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef93473",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_feature = pd.concat([impt_fe,l2_feature],axis=1)\n",
    "meta_feature_std = pd.concat([impt_fe_std,l2_feature_std],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ac4d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score3.loc[x.__name__,'meta']=cross_validation(meta_feature, label_train, x)\n",
    "    print(x.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fea6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in models:\n",
    "    score3.loc[x.__name__,'meta_std']=cross_validation(meta_feature, label_train, x)\n",
    "    print(x.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "score3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18fec1",
   "metadata": {},
   "source": [
    "### 9. check feature importance again using logist regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eef6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter = 20**9)\n",
    "LR.fit(new_feature,  np.array(label).T[0])\n",
    "feature_importance_LR = permutation_importance(LR, new_feature, np.array(label).T[0], n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LR = pd.DataFrame(feature_importance_LR.importances_mean, index = new_feature.columns, columns = ['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LR.loc[fi_LR['importance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4176a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feature_LR = new_feature[fi_LR.loc[fi_LR['importance']>0].index]\n",
    "unimportant_feature_LR = new_feature[fi_LR.loc[fi_LR['importance']<=0].index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1ba9d",
   "metadata": {},
   "source": [
    "### 10. created final_feature by using unimportant_feature to produce a new stacking feature, and add it on important_feature_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gradientBoosting to make level 1 prediction produces better result instead of Logist\n",
    "unimportant_feature_LR_st = pd.DataFrame(level_1_predictor(unimportant_feature_LR,np_label.T[0], GradientBoostingClassifier),columns=['unimportant_feature_LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436de54d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_feature = pd.concat([important_feature_LR,unimportant_feature_LR_st], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46224a4f",
   "metadata": {},
   "source": [
    "### 11.  Final test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7273920",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_feature,label, test_size=0.2, random_state=11)\n",
    "cross_validation(5,X_train, y_train, roc_auc_score,LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c99a4",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c03703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create important_l1 file\n",
    "dic = {}\n",
    "for x in feature.columns:\n",
    "    dic[x]=[0]\n",
    "i = pd.DataFrame(dic)\n",
    "i.to_csv('important_l1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de14d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.read_csv('important_l1.csv')\n",
    "for x in important_l1:\n",
    "    i[x]+=1\n",
    "i.to_csv('important_l1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b04190",
   "metadata": {},
   "source": [
    "### experiments and draft code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95aa1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fillNa(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        for x in feature.columns:\n",
    "            feature[x]=feature[x].fillna(feature[x].mean())\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1013ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_label(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d091667",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df = pd.read_csv(r'C:\\Users\\johnk\\OneDrive\\Desktop\\project\\python project\\kaggle\\amex-default-prediction\\new_train\\train_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21525a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = df.loc[df['target']==1].shape[0]\n",
    "negative = df.loc[df['target']==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b02c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = positive/(positive+negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa5d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-0.05/rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81217e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_label = np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee58a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_features = stacker(feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f9777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stack_feature,label, test_size=0.2, random_state=11)\n",
    "for x in models:\n",
    "    print(x.__name__,cross_validation(5,X_train, y_train, roc_auc_score,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6fdad0",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15158247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040d4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(label).T[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90460682",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "LR = LogisticRegression(max_iter = 20**9)\n",
    "LR.fit(feature,  np.array(label).T[0])\n",
    "feature_importance_LR = permutation_importance(LR, feature, np.array(label).T[0], n_repeats=10)\n",
    "print(\" %s second \" %(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LR = pd.DataFrame(feature_importance_LR.importances_mean, index = feature.columns, columns = ['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c8013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_feature = feature[fi.loc[fi['importance']==0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73caf8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_feature_LR = feature[fi_LR.loc[fi_LR['importance']>0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8eff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "unimportant_feature_LR = feature[fi_LR.loc[fi_LR['importance']<=0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63b06c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(unimportant_feature,label, test_size=0.2, random_state=11)\n",
    "for x in models:\n",
    "    print(x.__name__,cross_validation(5,X_train, y_train, roc_auc_score,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1436913",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(important_feature,label, test_size=0.2, random_state=11)\n",
    "for x in [GradientBoostingClassifier]:\n",
    "    print(x.__name__,cross_validation(5,X_train, y_train, roc_auc_score,x))\n",
    "print(\" %s second \" %str(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07abcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets_U ={'delinquency':delinquency,'spend':spend,'payment':payment,'balance':balance,'risk':risk,'std':std,'mean':mean, '_25':_25, '_50':_50, '_75':_75,'_min':_min,'_max':_max,'unimportant_feature':unimportant_feature.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39de4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c423399",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GradientBoostingClassifier,RandomForestClassifier,LogisticRegression]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4d5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature = pd.concat([important_feature,stack_features, unimportant_feature],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dae305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_feature,label, test_size=0.2, random_state=11)\n",
    "for x in models:\n",
    "    print(x.__name__,cross_validation(5,X_train, y_train, roc_auc_score,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(max_iter = 20**9)\n",
    "LR.fit(new_feature,  np.array(label).T[0])\n",
    "feature_importance_LR = permutation_importance(LR, new_feature, np.array(label).T[0], n_repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29051a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LR = pd.DataFrame(feature_importance_LR.importances_mean, index = new_feature.columns, columns = ['importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_feature = new_feature[fi_LR.loc[fi_LR['importance']>0].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1dab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(better_feature,label, test_size=0.2, random_state=11)\n",
    "for x in models:\n",
    "    print(x.__name__,cross_validation(5,X_train, y_train, roc_auc_score,x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69a3ae9",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef5ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_LR.loc[fi_LR['importance']>0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
